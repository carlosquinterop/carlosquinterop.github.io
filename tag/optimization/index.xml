<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Optimization | Carlos Quintero-Pe√±a</title>
    <link>https://carlosquinterop.github.io/tag/optimization/</link>
      <atom:link href="https://carlosquinterop.github.io/tag/optimization/index.xml" rel="self" type="application/rss+xml" />
    <description>Optimization</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 11 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://carlosquinterop.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Optimization</title>
      <link>https://carlosquinterop.github.io/tag/optimization/</link>
    </image>
    
    <item>
      <title>Optimal Grasps and Placements for Task and Motion Planning in Clutter,</title>
      <link>https://carlosquinterop.github.io/project/tamp-clutter/</link>
      <pubDate>Wed, 11 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://carlosquinterop.github.io/project/tamp-clutter/</guid>
      <description>&lt;p&gt;Planning for sequential manipulation in robotics is paramount. This is typically achieved by a layered planning approach (called Task and Motion Planning - TAMP) where a &lt;em&gt;skeleton&lt;/em&gt; is computed by a task planner first and then the robot motions for the actions within this skeleton are computed by a motion planner. Before the motions can be computed, continuous values of the action parameters need to be first resolved (this is called &lt;em&gt;&lt;strong&gt;grounding&lt;/strong&gt;&lt;/em&gt;). For example, to compute the motion to pick up an object, the grasp pose (i.e. the relative pose of the robot&amp;rsquo;s end-effector with respect to the object) needs to be computed first. To place an object in a surface, the new object location is required. Most TAMP frameworks rely on specialized samplers to obtain these parameters and they do not consider complex geometric constraints that can arise in the presence of cluttered environments. We contribute a specialized grounder for placements and grasps that considers all the actions of a plan skeleton &lt;em&gt;jointly&lt;/em&gt; for problems of planar manipulation under heavy cluttered scenes.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-a-baseline-tamp-with-grounder-based-on-random-sampling-b-our-approach-is-based-on-convex-optimization-of-the-whole-plan-skeleton&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/tamp-clutter/opt-frame_hufbd6a464d4280608a52944d6d37b21c2_201420_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;a) Baseline TAMP with grounder based on random sampling. b) Our approach is based on convex optimization of the whole plan skeleton&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/tamp-clutter/opt-frame_hufbd6a464d4280608a52944d6d37b21c2_201420_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2364&#34; height=&#34;994&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    a) Baseline TAMP with grounder based on random sampling. b) Our approach is based on convex optimization of the whole plan skeleton
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Our grounder is designed to solve problems of planar manipulation, where the robot is required to pick up and place a sequence of objects on a surface and there is potentially many objects of different heights. Additionally, we argue that these problems are hard because they have a very little amount of free space to be used as intermediate placement locations for objects. This setup is similar to a problem known as Object Rearrangement (OR), but unlike OR, we do not assume action feasibility, i.e., the robot hand may collide with another object when placing the grasped object due to their geometry. Additionally, our setup considers other scenarios where objects can be stacked on top of other objects (i.e., high-level actions other than pick and place are considered).&lt;/p&gt;
&lt;h2 id=&#34;our-solution&#34;&gt;Our solution&lt;/h2&gt;
&lt;p&gt;To solve these problems we propose a specialized grounder that is formulated as an optimization problem over the joint variables of candidate plan skeletons. We describe feasibility constraints (no collision) as non overlapping primitive shapes over conservative approximations of the projections of the robot hand and the objects (see figure below). By performing this simplification, we are able to write problems that can be solved up to global optimality very efficiently. Furthermore, infeasibility of our optimization formulations provides useful information that we use to prune the task space to find plan skeletons that are more likely to be feasible.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-geometric-primitives-circles-and-aabbs-are-used-as-conservative-approximations-of-the-robot-hand-and-objects-geometry-on-the-supporting-surface-feasibility-constraints-are-defined-as-non-intersection-of-pairs-of-primitives-along-the-plan-skeleton-the-resulting-optimization-problems-can-be-solved-to-global-optimality&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/tamp-clutter/formulation_huf52dba19cb0c6469a9cf3147d348093a_3336008_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Geometric primitives (circles and AABBs) are used as conservative approximations of the robot hand and objects&amp;amp;rsquo; geometry on the supporting surface. Feasibility constraints are defined as non-intersection of pairs of primitives along the plan skeleton. The resulting optimization problems can be solved to global optimality.&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/tamp-clutter/formulation_huf52dba19cb0c6469a9cf3147d348093a_3336008_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;5082&#34; height=&#34;1605&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Geometric primitives (circles and AABBs) are used as conservative approximations of the robot hand and objects&amp;rsquo; geometry on the supporting surface. Feasibility constraints are defined as non-intersection of pairs of primitives along the plan skeleton. The resulting optimization problems can be solved to global optimality.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;challenging-problems&#34;&gt;Challenging problems&lt;/h2&gt;
&lt;p&gt;The proposed problems are hard due to the high clutter and small amount of free space to place objects. Additional geometric constraints arise when the robot tries to pick up a short object next to a tall object since the robot geometry may collide with the neighbor object.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obstructed Pick X (OP-X): a short object that is surrounded by tall objects needs to be grasped and placed in a given goal location. All other objects doe not have a specified goal. This experiment is increasingly hard for high values of X and we show up to OP-9.&lt;/li&gt;
&lt;li&gt;Chessboard (Chess): The robot needs to set up the blue pieces of the chess in the starting configuration. For each piece, we compute a cylinder that fully contains the mesh representation to express the feasibility constraints and use the circle of its base as geometric primitive.&lt;/li&gt;
&lt;li&gt;Tower Assembling (Tower): The robot needs to assemble a tower with three blocks at a goal location in the given order. Before that, the objects are stacked and therefore they need to be unstacked first. When unstacking them, intermediate locations are needed and other objects on the surface need to be avoided. This is an example of a task that involves highl-level actions other than pick and place (stack and unstack).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/aVQhignxBlw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/1Cp5NzTTaX0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human-Guided Motion Planning in Partially Observable Environments</title>
      <link>https://carlosquinterop.github.io/project/blind/</link>
      <pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://carlosquinterop.github.io/project/blind/</guid>
      <description>&lt;p&gt;This project is concerned with the problem of motion planning for high-DOF robots under partial observability using guidance from humans.
We have proposed Bayesian Learning in the Dark (BLIND), an algorithm that leverages the human senses to compute high-DOF robot trajectories that are safe despite partial observability of the environment.
The main components that made up BLIND are shown next&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-blind-algorithm&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/blind/BLIND-pipeline_hua1dacfa157fa222ffe93d595be1c08bf_1409506_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;BLIND algorithm&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/blind/BLIND-pipeline_hua1dacfa157fa222ffe93d595be1c08bf_1409506_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;5609&#34; height=&#34;2757&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    BLIND algorithm
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The construction of a low-dimensional discrete state space and the guided motion planner are the two main novelties within BLIND.
The former leverages projections and sampling-based motion planners to create a space where reward learning can be performed. The latter uses optimization-based motion planning to incorporate the knowledge learned from the human as motion constraints.&lt;br&gt;
These two together enable reward learning techniques to be used using critiques to learn and compute high-dimensional safe trajectories despite the incomplete environmental information.&lt;/p&gt;
&lt;p&gt;The results show that BLIND outperforms state-of-the-art methods in teaching effort, success rate and path length.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-results-of-simulated-experiments-in-the-box-and-stove-environments&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/blind/results_hu4705a3750929e7e6469c92fb5173704f_331451_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Results of simulated experiments in the Box and Stove environments&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/blind/results_hu4705a3750929e7e6469c92fb5173704f_331451_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1419&#34; height=&#34;674&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Results of simulated experiments in the Box and Stove environments
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Check out our video of a robot implementation of BLIND, where a human user is asked to critique trajectories that are potentially unsafe. BLIND is executed in real-time and it converges to a safe solution.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/RbDDiApQhNo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Can Theoretical Algorithms Efficiently Escape Saddle Points in Deep Learning?</title>
      <link>https://carlosquinterop.github.io/project/example/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://carlosquinterop.github.io/project/example/</guid>
      <description>&lt;p&gt;This project provides a literature review for the most important recent works related to optimizing high-dimensional non-convex functions in the presence of saddle points mostly for machine learning applications.&lt;/p&gt;
&lt;p&gt;The inspiration came from reviewing the paper &amp;ldquo;How to Escape Saddle Points Efficiently?&amp;rdquo;. A large research effort has been devoted to proposed methods that can converge to second order stationary points efficiently. Of special interest is the set of methods that do not rely on Hessian computation, mainly driven by applications in machine learning where this may not be feasible. Although, many important theoretical results have been proposed, many of them have not be tested in real experiments, especially in the context of training a deep neural network. We have designed experiments with different network architectures and state-of-the-art datasets to observe the behavior of perturbed versions of gradient descent. Initial results show that an improvement in experimental convergence rate can be seen only for small and shallow networks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Motion Planning under Sensing Uncertainty</title>
      <link>https://carlosquinterop.github.io/project/sensing_uncertainty/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://carlosquinterop.github.io/project/sensing_uncertainty/</guid>
      <description>&lt;p&gt;Motion planning for high degree-of-freedom ( DOF ) robots is challenging, especially when acting in complex environments under sensing uncertainty. While there is significant work on how to plan under state uncertainty for low- DOF robots, existing methods cannot be easily translated into the high-DOF case, due to the complex geometry of the robot‚Äôs body and its environment.&lt;/p&gt;
&lt;p&gt;The figure above shows an example of a Fetch robot performing manipulation tasks in a table environment. The objects on top of the table are subject to sensing uncertainty in the direction shown by the arrow. The objective is to find a plan to move the green can from its starting position (to the left of the robot) to its goal position, while taking into account the object&amp;rsquo;s uncertainty.
The shown trajectory was computed by our proposed method Robust Optimization-based Motion Planner (ROMP).&lt;/p&gt;
&lt;p&gt;When we have perfect information about the location of objects in a given scene, motion planning methods provide an efficient way to solve our high-DOF manipulation problem. Sampling-based and Optimization-based methods stand out for this task. The former methods, build connectivity information in the robot&amp;rsquo;s configuration space by means of random sample and use such information to find a path between start and goal. The latter methods optimize cost functions that encourage smooth trajectories constrained to stay collision-free. RRT-Connect and TrajOpt are representatives of each category.&lt;/p&gt;
&lt;p&gt;The figure below shows top views of Fetch trajectories found by RRT-Connect, TrajOpt and the proposed ROMP, for our manipulation example. Importantly for this application, all planners generate trajectories that go close to the noisy obstacle. This is achieved by using a shortcut heuristic to the plan returned by RRT-Connect. TrajOpt on the other hand naturally encourages short trajectories. It can be seen that ROMP&amp;rsquo;s trajectory stays further away from the noisy object.&lt;/p&gt;
&lt;p&gt;The target here is not to compare the proposed approach with existing methods. That would not be a fair comparison since they are unaware of the obstacles&amp;rsquo; uncertainty. Our objective is to provide a method to incorporate this type of uncertainty when planning and highlight its benefits compared to not taking the uncertainty into account.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-top-view-of-trajectories-generated-by-different-planners-in-the-manipulation-task&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/FetchFront_hud4235b7ca7007213d0cc402bf8f38ff2_452583_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Top view of trajectories generated by different planners in the manipulation task&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/FetchFront_hud4235b7ca7007213d0cc402bf8f38ff2_452583_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1322&#34; height=&#34;640&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Top view of trajectories generated by different planners in the manipulation task
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;how-does-romp-work&#34;&gt;How does ROMP work?&lt;/h2&gt;
&lt;p&gt;ROMP can be thought of as an extension of optimization-based planners to account for uncertainty information. It is based on sequential convex optimization (SCO), where the non-convex collision avoidance constraints are linearized around the current solution and a quadratic program is solved at every iteration. A key difference with respect to optimization-based uncertainty unaware planners (e.g., TrajOpt) is that at every iteration of the SCO problem, ROMP creates a robust optimization formulation that protects the solution of the convex subproblem to uncertainty in the problem parameters. The uncertainty of this parameters comes from the uncertainty in the signed distance function between the noisy obstacle and the robot&amp;rsquo;s links and is assumed to be bounded. In its current version, the uncertain parameters lie in a cardinality constrained set.&lt;/p&gt;
&lt;p&gt;Two important aspects make ROMP attractive to be used for robust motion planning. On one hand, it can be applied to high-DOF robots since its formulation leverages the signed distance collision-avoidance constraints proposed by the authors of TrajOpt. Other robust planners in the literature assume that the robot can be modeled as a point in the task space. This assumption works well for applications where the robot&amp;rsquo;s body is small compared to its environment (e.g., drones or small car-like robots), but is not suitable for manipulators made of complex geometry. On the other hand, ROMP does not require the sensing uncertainty to be modeled using Gaussian noise (or other specific type of probability distribution). Its only assumption is that the uncertainty of the parameters is bounded and that one can have access to sample from the distribution. Most methods in the literature require the Gaussianity assumption, which may limit their applicability.&lt;/p&gt;
&lt;p&gt;At each iteration, ROMP solves the following convex optimization problem:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-robust-optimization-convex-subproblem-solved-by-romp&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/Formulation_hub51e6b2315bd2a9997b8fad7e1caef64_30633_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Robust Optimization convex subproblem solved by ROMP&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/Formulation_hub51e6b2315bd2a9997b8fad7e1caef64_30633_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;600&#34; height=&#34;181&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Robust Optimization convex subproblem solved by ROMP
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The parameters of this robust formulation need to be estimated at every iteration. This can be achieved by allowing ROMP to sample from the distribution of the noisy objects and keeping the maximum deviation of each parameters from its expected value. ROMP also modifies the actual merit function to account for the additional robust terms being added to the convex subproblems to enable convergence of the SCO algorithm.&lt;/p&gt;
&lt;h2 id=&#34;some-experiments&#34;&gt;Some experiments&lt;/h2&gt;
&lt;p&gt;We performed experiments to assess the performance of ROMP to a different set of noise models. To this end, we created a nominal scene of the fetch robot example and solved the motion planning problem using RRT-Connect, TrajOpt and ROMP. Then, we evaluated the probability of collision of such trajectories for both Gaussian and Uniform noise for a wide set of the distribution parameters using Monte Carlo experiments for 5000 samples for each distribution. The results can be shown in the figure below:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-monte-carlo-results-for-the-uncertain-motion-planning-manipulation-task&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/fetch_translational_results_hu91884ff7bef662116ba39e4cb4d3a611_204645_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Monte Carlo results for the uncertain motion planning manipulation task&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/fetch_translational_results_hu91884ff7bef662116ba39e4cb4d3a611_204645_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1753&#34; height=&#34;497&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Monte Carlo results for the uncertain motion planning manipulation task
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;It can be seen that ROMP successfully maintain a low probability of collision for all the distribution parameters (Gaussian on the left, Uniform on the center). Additionally, the figure on the right shows the average distance to collision between the robot and the noisy object for each trajectory waypoint and its standard deviation for both TrajOpt and ROMP.&lt;/p&gt;
&lt;p&gt;The figure below show examples of more trajectories computed by the planners for the same task but when the grasp pose is different.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-robust-optimization-convex-subproblem-solved-by-romp&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/FetchTop_hue0ec0193e3d4fa08636043586b129210_444430_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Robust Optimization convex subproblem solved by ROMP&#34;&gt;


  &lt;img data-src=&#34;https://carlosquinterop.github.io/project/sensing_uncertainty/FetchTop_hue0ec0193e3d4fa08636043586b129210_444430_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1663&#34; height=&#34;760&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Robust Optimization convex subproblem solved by ROMP
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;It can be noticed that similar to the previous example, RRT-Connect and TrajOpt find trajectories that go very close to the obstacle. ROMP however, pushes the trajectory closer to the robot&amp;rsquo;s body to account for the uncertainty in the direction of the noise. The following video shows the trajectory traces.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/IUuDnYvw2Ow&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
